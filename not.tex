\section{Notations and Definitions}\label{sec:def}
We denote the sets real and complex numbers by $\R$ and $\C$ respectively. For $x\in \C$ we denote its modulus and complex conjugate by $\md{x}$ and $\bar{x}$ respectively. We denote $d$-dimensional vector spaces over $\R$ and $\C$ by $\R^{d}$ and $\C^{d}$ respectively, and use $\R^{\dcd}$ and $\C^{\dcd}$ to denote $\dcd$ matrices with real and complex entries respectively. We denote the transpose of $x$ by $x^\top$ and the conjugate transpose by $x^*={\bar{x}}^\top$. We will use $\ip{\cdot,\cdot}$ to denote the inner products: $\ip{x,y}=x^* y$. For $x\in\C^d$, we denote the general quadratic norm with respect to a Hermitian matrix $C$ by $\norm{x}^2_C\eqdef x^*\, C \,x$.
The norm of the matrix $A$ is given by $\norm{A}\eqdef \sup_{x\in \C^d:\norm{x}=1} \norm{Ax}$.  We use $\cond{A}=\norm{A}\norm{A^{-1}}$ to denote the condition number of the matrix $A$. We denote the identity matrix in $\C^{\dcd}$ by $\I$ and the set of invertible $\dcd$ complex matrices by $\gld$.
For a positive real number $B>0$, we denote by $\C^{d}_B=\{b\in \C^d\mid \norm{b}\leq B\}$ and by $\C^{\dcd}_B=\{A\in \C^{\dcd}\mid \norm{A}\leq B\}$ the set of complex vectors and matrices whose norms are bounded $B$.
We use $\left(\cdot\right)\sim P$ to denote the fact that $\left(\cdot\right)$ is distributed according to probability distribution $P$.
$\E$ denotes mathematical expectation.
\begin{definition}\label{def:dist}
Let $P=(P^V,P^M)$ denote a $2$-tuple of probability distributions; $P^V$ over $\C^{d}$ and $P^M$ over $\C^{\dcd}$. Define
\begin{align*}
A_P&=\int M dP^M(M),\quad C_P=\int M^* M dP^M(M), \quad b_P=\int V dP^V(V)\\
\rhod{P}&\eqdef {\inf}_{x\in\C^d\colon\norm{x}=1}\ip{x,\left((A_P+A_P^*)-\alpha A_P^* A_P\right)x},\\ \rhos{P}&\eqdef{\inf}_{x\in \C^d\colon\norm{x}=1}\ip{x,\left((A_P+A_P^*)-\alpha C_P\right)x}
\end{align*}
\end{definition}
Note that $\rhod{P}>\rhos{P}$.
\begin{definition}\label{def:simdist}
Let $P=(P^V,P^M)$ as in \Cref{def:dist}; $b\sim P^V$ and $A\sim \P^M$ be random variables distributed according to $P^V$ and $P^M$. For $U\in \gld$ define $P_U\eqdef(P_U^V,P_U^M)$, to be the distributions of $U^{-1}b$ and $U^{-1}AU$.
\end{definition}
\begin{definition}
We call a matrix $A\in \C^{\dcd}$ to be \emph{Hurwitz} (H) if all eigenvalues of $A$ have positive real parts. We call a matrix $A\in \C^{\dcd}$ to be \emph{Positive Definite} (PD) if $\ip{x,Ax} >0,\,\forall x\neq 0 \in \C^{d}$.  We call a matrix $A\in \C^{\dcd}$ to be \emph{Symmetric Positive Definite} (SPD) is it is symmetric i.e., $A^\top=A$ and PD.
\end{definition}
\begin{definition}\label{distpd}
We call the distribution $P$ in \Cref{def:dist} to be H/PD/SPD if $A_P$ is H/PD/SPD.
\end{definition}
\begin{example}
The matrices $\begin{bmatrix}0.1 &-1\\ 1 & 0.1\end{bmatrix}$, $\begin{bmatrix} 0.1 & 0.1 \\ 0 & 0.1\end{bmatrix}$ and $\begin{bmatrix}0.1 &0 \\ 0 & 0.1\end{bmatrix}$ are examples of H, PD and SPD respectively.
\end{example}

\begin{definition}
Call a set of distributions $\P=(\P^V,\P^M)$ over $\C^{d}\times \C^{\dcd}$
\emph{weakly admissible} if there exists $\alpha_{\P}>0$ such that
$\rhos{P}>0,\forall \alpha\in(0,\alpha_{\P})$ holds for all $P\in \P$.
\end{definition}
\begin{definition}
Call a set of distributions $\P=(\P^V,\P^M)$ over $\C^{d}\times \C^{\dcd}$ \emph{admissible}
if there exists some $\alpha_{\P}>0$ such that $\inf_{P\in \P} \rhos{P}>0,\,\forall \alpha\in(0,\alpha_{\P})$.
The value of $\alpha_{\P}$ is called a witness.
\end{definition}

It is easy to see that $\alpha \mapsto \rhos{P}$ is decreasing,
hence if $\alpha_{\P}>0$ witnesses that $\P$ is (weakly) admissible
then any $0<\alpha'\le \alpha_{\P}$ is also witnessing this.
