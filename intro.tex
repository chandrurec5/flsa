\section{Introduction}
We consider linear stochastic approximation algorithms (LSA) of the general form given by
\begin{align}\label{eq:lsaintro}
\theta_t=\theta_{t-1}+\alpha_t (b_t-A_t \theta_{t-1}),
\end{align}
where the iterates, $\theta_t\in \R^d$, and step-sizes, $\alpha_t>0$, are algorithmic quantities, and $(b_t,A_t), t\geq 0\in \R^d\times \R^{\dcd}$ is the noisy data sequence presented to the algorithm.
LSAs are widely applied in machine learning and reinforcement learning (RL), where the aim is to compute an appropriate $\ts\in \R^d$ using only the noisy data sequence and $O(d)$ updates per iteration. Some examples of LSAs include the stochastic gradient descent algorithm (SGD) for the problem of linear regression with quadratic loss \cite{bach,bachaistats}, and the \emph{temporal difference} (TD) class of learning algorithms in RL \cite{sutton,konda-tsitsiklis,gtd,gtd2,gtdmp}.\par
%An additional feature in these class of applications is that $A_t$ turns out to be a rank-$1$ matrix and $A_t\theta_{t-1}$ can be obtained in $O(d)$, which is attractive due to the cheap per time step computational requirement.\par

The choice of the step-sizes $\alpha_t$ is critical for the performance of LSAs such as \eqref{eq:lsaintro}.
Informally speaking, smaller step-sizes are better for noise rejection and larger step-sizes lead to faster learning, and at the same time, step-sizes that are too large might result in instability of \eqref{eq:lsaintro}. A useful choice in RL has been the diminishing step-sizes \cite{gtd2,gtdmp,konda-tsitsiklis}, where $\alpha_t\ra 0$ such that $\sum_{t\geq 0} \alpha_t=\infty$. An alternate technique, which we call LSA with constant step-size and Polyak-Ruppert (CS-PR) averaging, is to run \eqref{eq:lsaintro} as a constant step-size LSA by choosing $\alpha_t=\alpha>0,\forall t\geq 0$, and output the average $\thh_t\eqdef\frac{1}{t+1}\sum_{i=0}^t \theta_i$. In LSA with CS-PR, $\theta_t$ is an internal variable and $\thh_t$ is the output of the algorithm. The idea of averaging in stochastic approximation to improve noise rejection is a technique that goes back to  \citet{ruppert} and \citet{polyak-judisky}. Intuitively, the CS-PR technique can be seen to address the learning vs noise rejection trade-off, where the constant step-size takes care of the learning  and the averaging of the iterates takes care of the noise rejection.
\paragraph{Motivation and Contribution:} Recently, \citet{bach} considered SGD\footnote{SGD is an LSA of the form in \eqref{eq:lsaintro}.} with CS-PR for the linear regression problem with quadratic loss and $i.i.d$ sampling. A ``remarkable'' result by \citet{bach} is that there exists a constant step-size such that for any problem where the noisy data is bounded by a known constant, the mean squared (regression) error after $t$ updates is at most $\frac{C}{t}$ with a constant $C>0$ that depends \emph{only} on the bound on the data.\par\todoc{Dimension?}
In this paper, we study LSAs with CS-PR (thereby extending prior work by \citet{bach} from SGD to general LSAs) where the data sequence $(b_t,A_t),t\geq 0$ is $i.i.d$ with some underlying distribution $P$ such that the variance is bounded. An additional restriction we place on $P$ is that the matrix $\EEP{A_t}$ is Hurwitz, i.e., all its eigenvalues have positive real parts.
Our study is motivated by the problem of \emph{policy evaluation} \cite{dann} using linear value function approximation from experience replay \cite{lin} in a batch setting \cite{lange} in RL using TD class  of algorithms \cite{sutton,konda-tsitsiklis,gtd,gtd2,gtdmp}. Here, we wish to understand the effectiveness of the CS-PR technique for the TD class of LSA algorithms used in RL.
We now list our contributions in this paper as follows:
%While asymptotically diminishing step-sizes are common in RL literature \cite{ilstd,gtdmp,korda-prashanth}, the constant step-size choice has also been used in the past \cite{gtd2}.
\begin{itemize}[leftmargin=*]%, before = \leavevmode\vspace{-\baselineskip}]
\item \textbf{Instance Dependent Bounds:} For a given $P$, we  measure the performance of a given LSA with CS-PR in terms of the mean square error (MSE) given by $\EEP{\norm{\thh_t-\ts}^2}$. We show that there exists an $\alpha_P>0$ such that the mean squared error (MSE) %of a given LSA with CS-PR
is at most $O(\frac{1}{t})$, whenever $\alpha\in (0,\alpha_P)$.
%The MSE can further be broken down to a \emph{bias} term (arising due to the initial condition $\theta_0$) that decays at a rate $O(\frac{1}{t^2})$ and a \emph{variance} term (due to the noise) that decays at at rate $O(\frac{1}{t})$.
\item \textbf{Uniform Step-Sizes:} It is of interest to know that for a given LSA with CS-PR and a given class $\P$ of distributions, whether it is possible to ensure uniform performance $\forall P\in \P$. We also show (via an example) that there is a class $\P$ that does not `admit' a constant step-size $\alpha_{\P}$ that guarantees uniform performance $\forall P\in \P$. This is a negative result in the context of RL. However, we also argue that the subclass (which we denote by $\P_{\text{SPD},B}$) related to SGD for linear regression does `admit' a uniform constant step-size, thereby recovering a part of the result by \citet{bach}.
\item \textbf{Automatic Step-Size:} We argue informally that for any given $P$, a constant step-size can be chosen in an `automated' fashion. This way we argue that the performance of LSA with CS-PR is comparable to other popular step-size choices used for LSAs arising in RL.
\end{itemize}
\paragraph{Implications:} In addition to TD(0), our results directly can be applied to a host of \emph{off-policy} TD algorithms such as GTD/GTD2/TDC with CS-PR. In the case of TDC only asymptotic bounds were known \cite{gtd2} and our results are a first step towards proving finite time bounds. Also, our results show that the GTD class of algorithms guarantee a $O(\frac{1}{t})$ rate for MSE (without use of projections) as opposed to the previous results (using projections) \cite{gtdmp} that provide a $O(\frac{1}{\sqrt{t}})$ rate for this class.
\paragraph{Organization:} The paper is organized as follows
