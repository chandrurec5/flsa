\section{Introduction}
Stochastic Approximation (SA) algorithms can be expressed in the general form
\begin{align}\label{eq:sa}
\theta_t=\theta_{t-1}+\alpha_t f(\theta_{t-1},\zeta_t),
\end{align}
where $\theta_t\in \R^d$ are the iterates, and $f(\theta_{t-1},\zeta_t)$ of the function $g(\theta_{t-1})=\EE{f(\theta_{t-1})}_{\zeta_t}$, where the expectation is with respect to some noise process $\zeta_t$. At each time step, the algorithm updates the iterates in increments proportional to a step-size $\alpha_t>0$ and the idea is to eventually converge to $\ts\in \R^d$ which is a desired optimum or a fixed point. Due to their inherent online nature SA algorithms appear widely in machine learning applications \cite{konda,bhatnagar,borkar,gtd,td,bach}, where we have to learn from a noisy data stream.\par
The choice of the step-size $\alpha_t$ needs to trade-off learning rate versus filtering noise, so to speak. In general, one can guess that larger step-size lead to faster learning and at the same time smaller step-sizes are better to handle noise. A popular choice of step-size schedule that is known handle the noise $\alpha_t=O(\frac{1}{t})$. However, since the step size are diminishing, it can hurt the learning rate. An alternative suggestion is to use more aggressive step sizes without minding the noise in the iterates $\theta_t$ in \eqref{eq:sa}, however, introduce additional averaging (known as Polyak-Rupert averaging) to filter the noise. The averaged iterates can be given by $\th_t\eqdef\frac{1}{t}\sum_{s=0}^t \theta_t$, and an analysis of the PR-averaging technique is known from \cite{}.\par
A host of algorithms in machine learning and in particular, the temporal difference class of algorithms arising in reinforcement learning, turn out to be special cases of \eqref{eq:sa}, namley linear stochastic approximation (LSA) algorithms. LSA algorithms assume the general form
\begin{align}\label{eq:lsaintro}
\theta_t=\theta_{t-1}+\alpha_t (b_t-A_t \theta_{t-1}),
\end{align}
where $b_t\in \R^d$ and $A_t\in \R^{\dcd}$ are data dependent quantities that are preseneted to the learner in a sequential manner. Further, in most instances of LSA $A_t$ turns out to be a rank-$1$ matrix and $A_t\theta_{t-1}$ can be computed in $O(n)$, and are desired for this low per iteration computational cost. Recently, \cite{bach} used \eqref{eq:lsaintro} with constant step-size, i.e., $\alpha_t=\alpha,\,\forall t\geq 0, \, \alpha >0$ and PR-averaging for the linear prediction problem with squared loss and $i.i.d$ sampling. A ``remarkable'' result by \cite{bach} is that there exists a constant step-size such that for any problem where the noisy data is bounded by a known constant, he expected squared prediction error after $t$ updates is at most $\frac{C}{t}$ with a constant $C>0$ that depends \emph{only} on the bound on the data.\todoc{Dimension?}
In particular, as opposed to many earlier results available in the literature \todoc{Add citations}, $C$ does \emph{not} depend on the conditioning of the underlying system, while the total runtime of the algorithm scales linearly with both $t$ and $n$.\par
In this paper, we want to understand the performance of constant step size with PR-average of iterates for general class of LSAs (outside of the linear prediction setting considered by \cite{bach}). We are interested in the problem of linear value function approximation in reinforcement learning using temporal difference learning (TD) either from experience replay in a batch setting or solving linear systems using TD-style algorithms.
\todoc{TD-style, or just TD?} \todoc{Later we need to comment on TD with eligibility traces and other variations of TD, e.g., new variants.} We now list our contributions, and its implications to the TD class of algorithms, and the key differences between the techniques employed here in comparison to \cite{bach}. We now list our contributions, the implications of our results, and the challenges presented by the general setting in comparison to the linear prediction setting considered by \cite{bach}.
\paragraph{Contributions}:
\begin{itemize}[leftmargin=*, before = \leavevmode\vspace{-\baselineskip}]
\item We show that in the case of general LSA, there exists instance dependent constant step size choice such that the mean squared error of the PR-average given by $\err_t=\EE{\norm{\thh_t-\ts}^2}$ is at most $O(\frac{1}{t})$. The error $\err_t$ further can be broken down to a \emph{bias} term (arising due to the initial condition $\theta_0$) that decays at a rate $O(\frac{1}{t^2})$ and a \emph{variance} term (due to the noise) that decays at at rate $O(\frac{1}{t})$.
\item We also show (via counter example) that not all classes of general LSAs `admit' a constant uniform step size. Further, we also argue that the subclass of LSAs related to linear prediction problem does `admit' a problem independent constant step size.
\end{itemize}
\paragraph{Implications:}
\begin{itemize}[leftmargin=*, before = \leavevmode\vspace{-\baselineskip}]
\item Our results hold under the weak assumption\footnote{When this weak assumption fails to hold, the LSA is unstable and hence the notion of convergence is void.} that all the eigen values of $\EE{A_t}$ have strictly real parts. This assumption holds for all known TD class of RL algorithms.
\item Two timescale LSA algorithms are those that use two set of iterates (namely slower and faster) and two separate step-size schedules. Our results also hold for two timescale LSAs as long as the two different step-sizes are held constant with respect to time. Thus our setting not only holds for TD(0) but also extends to GTD/GTD2 and TDC. This provides a unified view of the various temporal difference learning algorithms.
\item The intuition behind the error analysis can be explained in simple terms when the noise free case is considered (i.e., $A_t=A$ in \eqref{eq:lsaintro}). In this case, the LSA is just a linear time invariant dynamical system where the error $\theta_t-\ts=(I-\alpha A)^t (\theta_0-\ts)$ and $\norm{\theta_t-\ts}=\rho^t\norm{\theta_0-\ts}$ (for some $0<\rho<1$). Now the PR-average is given by $\frac{\norm{\theta_t-\ts}^2}{t^2}=\frac{\sum_{s=0}^{t-1}\rho^s}{t^2} \norm{\theta_0-\ts}^2$. Note that the numerator is just sum of terms of a geomteric series, which is summable as long as the matrix $(I-\alpha A)$ has eigen values within the unit circle.
\item The fact that the setting covers even two timescale LSAs with constant step size, coupled with the intuitive interpretation of the error dynamics together present a simple and unified view of the various temporal difference learning algroithms in literature.
\item One of the major bottlenecks in selecting step-size for general LSA is the lack of problem knoweldge. One way to handle this issue is to choose a diminishing step size schedule such as $\alpha_t=\frac{1}{t}$. However, such a strategy can fail when the underlying matrices are ill-conditioned (see \Cref{sec:stepsizes}). Another popular approach has been to choose $\alpha_t=\frac{c}{c+t}$, where initially the step-sizes are held almost constant and then as $t$ increases they decay at rate $O(\frac{1}{t})$. While this approach can mitigate the ill-conditioning problem, it can at the same time amplify the effect of noise. In this paper, we argue informally that the constant step-size with PR-averaging of iterates can be a promising way to mitigate these issues, by periodically checking for possible blow up of the norm of the iterates and then reducing the step-size based on this information (see \Cref{sec:stepsizes}).
\end{itemize}
\paragraph{Challenges:} The break up of error into bias and variance terms and their respective rates were previously worked out by \cite{bach} in the linear prediction setting, and here we extend the same to the general class of LSAs. Nevertheless, there are certain key differences between the general LSA setting that we consider to the setting considered by \cite{bach}, which are listed as under.
\begin{itemize}[leftmargin=*, before = \leavevmode\vspace{-\baselineskip}]
\item In the linear least-squares problem is considered by \citet{bachharder} and the random matrices involved are known to be symmetric positive definite. This enables \citet{bachharder} to define operators that act between spaces of \emph{symmetric} matrices and carry out the computations making use of such operators. In our case, the matrices are known only to be (laxly) positive definite, i.e., they lack symmetry. \todoc{We should point out after our analysis in which step the symmetry helps \citet{bachharder}. We should also make this somehow clear here if possible.}
Thus, the above approach does not work, and instead we have resort to an analysis that makes use of only the expected norms of the random matrices involved.
\item Another significant difference is that in linear least-squares, the ``noise'' has a favorable ``structure''. Again, due to the lack of symmetry, this favorable structure does not apply. \todoc{Again, after the analysis, we should point out how the structured noise would have helped. I am wondering whether a more graceful degradation should happen? Is this really all or nothing?}
\end{itemize}
