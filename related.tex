\section{Related Work}
\subsection{Linear Regression}
Let $(x_t,y_t)\in \R^n\times \R,\,t\geq 1$ be $i.i.d$ such that $\EE{\norm{x_t}^2}$ and $\EE{y_t^2}$ are finite. Further, we assume bounded data i.e., $\norm{(x_t,y_t)}^2\leq B$ for some positive real number $B>0$. Here, $x_t,\,t\geq 1$ are the features and $y_t$ are real labels and the linear regression problem constitutes minimizing the quadratic loss function $f(\theta)=\EE{\left(\ip{x_t,\theta}-y_t\right)^2}$. The stochastic gradient descent scheme with constant step size $\alpha>0$ to minimize $f(\theta)$ can be given as below:
\begin{align}\label{linreg}
\theta_t=\theta_{t-1}-\alpha x_t\left(\ip{x_t,\theta_{t-1} -y_t}\right)
\end{align}
Here $\nabla f(\theta_{t-1})=x_t\left(\ip{x_t,\theta_{t-1} -y_t}\right)$ is the \emph{stochastic gradient} of the objective $f(\theta)$. It follows from the $i.i.d$ assumption on $(x_t,y_t)$ that $A_t=x_t x_t^\top$ and $b_t=y_t x_t$ are also $i.i.d$, and with this identification one can see that \eqref{linreg} is of the form in \eqref{conststep}. In this case $A_P$ is SPD.
In the linear regression setting, the error of a parameter $\theta$ is measured as the difference between the loss at the said parameter and the loss at the optimum, which has the following form
\begin{align*}
f(\theta)-f(\ts)=(\theta-\ts)^\top A_P (\theta-\ts)=\EE{\norm{\theta-\ts}^2_{A_P}}
\end{align*}

\subsection{Reinforcement Learning}
\subsection{GTD}
\todoch{Use LiHong Li's GTD results, choice of the basis $U$ etc}
